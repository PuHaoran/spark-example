{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程\n",
    "\n",
    "#### 对连续值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------------+\n",
      "| id|feature|binarized_feature|\n",
      "+---+-------+-----------------+\n",
      "|  0|    1.1|              0.0|\n",
      "|  1|    8.5|              1.0|\n",
      "|  2|    5.2|              1.0|\n",
      "+---+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 二值化\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Binarizer\n",
    "\n",
    "# 为用户提供统一的切入点来使用spark的各项功能\n",
    "spark = SparkSession.builder.appName(\"BinarizerExample\").getOrCreate()\n",
    "\n",
    "data = [(0, 1.1), (1, 8.5), (2, 5.2)]\n",
    "continuous_dataframe = spark.createDataFrame(data, ['id', 'feature'])\n",
    "\n",
    "# 查看DataFrame数据\n",
    "continuous_dataframe.collect()\n",
    "\n",
    "# 构建binarizer并进行transform\n",
    "binarizer = Binarizer(threshold=4.0, \n",
    "                      inputCol=\"feature\", \n",
    "                      outputCol=\"binarized_feature\")\n",
    "\n",
    "binarized_dataframe = binarizer.transform(continuous_dataframe)\n",
    "binarizer.getThreshold()\n",
    "\n",
    "# 查看表信息\n",
    "binarized_dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|features|bucketed_features|\n",
      "+--------+-----------------+\n",
      "|   -99.2|              0.0|\n",
      "|    -0.5|              1.0|\n",
      "|    -1.5|              0.0|\n",
      "|     1.0|              3.0|\n",
      "|   100.0|              3.0|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. 按照给定边界离散化（分箱分桶）\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "spark = SparkSession.builder.appName(\"BucketizerExample\").getOrCreate()\n",
    "\n",
    "splits = [-float(\"inf\"), -0.5, 0.0, 0.5, float(\"inf\")]\n",
    "data = [(-99.2,), (-0.5,), (-1.5,), (1.0,), (100.0,)]\n",
    "data_frame = spark.createDataFrame(data, [\"features\"])\n",
    "\n",
    "bucketizer = Bucketizer(splits=splits, inputCol=\"features\", outputCol=\"bucketed_features\")\n",
    "bucketed_data = bucketizer.transform(data_frame)\n",
    "\n",
    "bucketed_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|hour|result|\n",
      "+---+----+------+\n",
      "|  0|18.0|   2.0|\n",
      "|  1|19.0|   2.0|\n",
      "|  2| 8.0|   1.0|\n",
      "|  3| 5.0|   0.0|\n",
      "|  4| 2.2|   0.0|\n",
      "|  5| 9.2|   1.0|\n",
      "|  6|14.4|   2.0|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. 按分位数离散化\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"QuantileDiscretizerExample\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "data = [(0, 18.0), (1, 19.0), (2, 8.0), (3, 5.0), (4, 2.2), (5, 9.2), (6, 14.4)]\n",
    "df = spark.createDataFrame(data, [\"id\", \"hour\"])\n",
    "\n",
    "discretizer = QuantileDiscretizer(numBuckets=3, inputCol=\"hour\", outputCol=\"result\")\n",
    "result = discretizer.fit(df).transform(df)\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
